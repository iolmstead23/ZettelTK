### Ten Commandments of [[Computer]] Ethics

Many ethical standards are already widely accepted throughout the world. One of the most notable is the Ten Commandments of [[Computer]] Ethics, dating to the early 1950s.

#### Ten Commandments of [[Computer]] Ethics

1. Thou shalt not use a [[computer]] to harm other people.
2. Thou shalt not interfere with other people's [[computer]] work.
3. Thou shalt not snoop around in other people's [[computer]] files.
4. Thou shalt not use a [[computer]] to steal.
5. Thou shalt not use a [[computer]] to bear false witness.
6. Thou shalt not copy or use proprietary [[Software|software]] for which you have not paid (without permission).
7. Thou shalt not use other people's [[computer]] resources without authorization or proper compensation.
8. Thou shalt not appropriate other people's intellectual output.
9. Thou shalt think about the social consequences of the program you are writing or the system you are designing.
10. Thou shalt always use a [[computer]] in ways that ensure consideration and respect for other humans.

Source: [The Ten Commandments of [[Computer]] Ethics (opens new tab)](http://cpsr.org/issues/ethics/cei/)

### Asimov's Three Laws of Robotics

Laws of robotics are a set of laws, rules, or principles that are intended as a fundamental framework to underpin the behavior of robots designed to have a degree of autonomy. Robots with a high degree of complexity do not yet exist, but they have been widely anticipated in science fiction and films and are a topic of active research and development in the fields of robotics and artificial intelligence. The best known set of laws are those written by Isaac Asimov in the 1940s, or are based upon them, but other sets of laws have been proposed by researchers in the decades since then.

#### Asimov's Three Laws of Robotics

1. A robot may not injure a human being or, through inaction, allow a human being to come to harm.
2. A robot must obey orders given it by human beings except where such orders would conflict with the First Law.
3. A robot must protect its own existence as long as such protection does not conflict with the First or Second Law.

Source: Asimov’s Three Laws of Robotics

Science fiction? Yes, but take a look at the 2011 Engineering and Physical Sciences Research Council (EPSRC) and the Arts and Humanities Research Council (AHRC) of Great Britain's set of five ethical "principles for designers, builders and users or robots:"

- Robots should not be designed solely or primarily to kill or harm humans.
- Humans, not robots, are responsible agents. Robots are tools designed to achieve human goals.
- Robots should be designed in ways that assure their safety and security.
- Robots are artifacts; they should not be designed to exploit vulnerable users by evoking an emotional response or dependency. It should always be possible to tell a robot from a human.
- It should always be possible to find out who is legally responsible for a robot.