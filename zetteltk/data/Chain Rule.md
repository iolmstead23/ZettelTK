The Chain Rule is a foundational concept in [[Calculus|calculus]], particularly useful for differentiating composite functions. When a [[function]] is formed by combining two other functions, such as $f(g(x))$the Chain Rule allows us to find the [[Derivative|derivative]] by considering the rate of change of each [[function]] involved. The rule states that if $y = f(g(x))$, then the [[Derivative|derivative]] $y' = f'(g(x)) \cdot g'(x)$. In other words, we differentiate the outer [[function]], $f$, while treating the inner [[function]], $g(x)$, as a single variable, and then multiply by the [[derivative]] of the inner [[function]]. This approach is essential for dealing with nested functions in [[Calculus|calculus]].

Historically, the Chain Rule has roots in the work of early [[calculus]] pioneers like [[Isaac Newton]] and [[Gottfried Wilhelm Leibniz]] in the 17th century. Although they did not formally define it in the way modern [[calculus]] does, their notation and ideas on rates of change laid the foundation. In the 19th century, mathematicians like Augustin-Louis Cauchy provided rigorous definitions for [[calculus]] principles, helping the Chain Rule become a formally recognized [[Differentiation|differentiation]] method.

In practice, the Chain Rule is widely applied across [[calculus]] and fields like physics, engineering, and economics, where processes often depend on multiple layers of functions. Whether for solving complex equations or finding gradients, the Chain Rule allows us to handle functions within functions, making it indispensable in both theoretical and applied [[Mathematics|mathematics]].